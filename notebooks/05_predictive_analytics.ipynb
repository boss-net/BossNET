{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Analytics for Educational Outcomes\n",
    "\n",
    "This notebook focuses on predicting educational outcomes and identifying key factors that influence student success in Bangladesh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('../processed_data/cleaned/cleaned_student_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def prepare_features(data):\n",
    "    \"\"\"Prepare features for predictive modeling.\"\"\"\n",
    "    # Create copy of data\n",
    "    df_model = data.copy()\n",
    "    \n",
    "    # Create target variable (success = GPA >= 3.0)\n",
    "    df_model['success'] = (df_model['gpa'] >= 3.0).astype(int)\n",
    "    \n",
    "    # Create derived features\n",
    "    df_model['attendance_category'] = pd.qcut(df_model['attendance_rate'], \n",
    "                                             q=4, labels=['Low', 'Medium', 'High', 'Very High'])\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    categorical_columns = ['division', 'gender', 'location_type', 'attendance_category']\n",
    "    df_model = pd.get_dummies(df_model, columns=categorical_columns)\n",
    "    \n",
    "    return df_model\n",
    "\n",
    "# Prepare features\n",
    "df_model = prepare_features(df)\n",
    "print(\"Features created:\")\n",
    "print(df_model.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def train_predict_model(data, target='success'):\n",
    "    \"\"\"Train and evaluate prediction model.\"\"\"\n",
    "    # Separate features and target\n",
    "    X = data.drop([target, 'gpa', 'student_id'], axis=1)\n",
    "    y = data[target]\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Train models\n",
    "    models = {\n",
    "        'logistic': LogisticRegression(),\n",
    "        'random_forest': RandomForestClassifier(n_estimators=100)\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        # Train model\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        \n",
    "        # Evaluate\n",
    "        results[name] = {\n",
    "            'classification_report': classification_report(y_test, y_pred),\n",
    "            'confusion_matrix': confusion_matrix(y_test, y_pred)\n",
    "        }\n",
    "        \n",
    "        # Feature importance (for random forest)\n",
    "        if name == 'random_forest':\n",
    "            feature_importance = pd.DataFrame({\n",
    "                'feature': X.columns,\n",
    "                'importance': model.feature_importances_\n",
    "            }).sort_values('importance', ascending=False)\n",
    "            results[name]['feature_importance'] = feature_importance\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Train and evaluate models\n",
    "model_results = train_predict_model(df_model)\n",
    "\n",
    "# Display results\n",
    "for model_name, result in model_results.items():\n",
    "    print(f\"\\nResults for {model_name}:\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(result['classification_report'])\n",
    "    \n",
    "    if 'feature_importance' in result:\n",
    "        print(\"\\nTop 10 Important Features:\")\n",
    "        print(result['feature_importance'].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Risk Factor Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def analyze_risk_factors(data, model_results):\n",
    "    \"\"\"Analyze factors that contribute to academic risk.\"\"\"\n",
    "    # Get feature importance\n",
    "    feature_importance = model_results['random_forest']['feature_importance']\n",
    "    \n",
    "    # Plot feature importance\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(data=feature_importance.head(10), x='importance', y='feature')\n",
    "    plt.title('Top 10 Factors Influencing Academic Success')\n",
    "    plt.show()\n",
    "    \n",
    "    # Analyze high-risk patterns\n",
    "    high_risk = data[data['success'] == 0]\n",
    "    low_risk = data[data['success'] == 1]\n",
    "    \n",
    "    # Compare distributions\n",
    "    for feature in feature_importance['feature'].head(5):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.kdeplot(data=high_risk, x=feature, label='High Risk')\n",
    "        sns.kdeplot(data=low_risk, x=feature, label='Low Risk')\n",
    "        plt.title(f'Distribution of {feature} by Risk Level')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "analyze_risk_factors(df_model, model_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Intervention Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def generate_recommendations(data, model_results):\n",
    "    \"\"\"Generate targeted intervention recommendations.\"\"\"\n",
    "    # Identify high-risk groups\n",
    "    risk_factors = model_results['random_forest']['feature_importance']\n",
    "    top_factors = risk_factors['feature'].head(5).tolist()\n",
    "    \n",
    "    # Analyze patterns in high-risk group\n",
    "    high_risk = data[data['success'] == 0]\n",
    "    \n",
    "    # Generate recommendations based on patterns\n",
    "    recommendations = {\n",
    "        'attendance': {\n",
    "            'pattern': high_risk['attendance_rate'].mean(),\n",
    "            'recommendation': 'Implement attendance monitoring and support system'\n",
    "        },\n",
    "        'resources': {\n",
    "            'pattern': high_risk['resource_access'].mean(),\n",
    "            'recommendation': 'Increase access to educational resources'\n",
    "        },\n",
    "        'support': {\n",
    "            'pattern': high_risk['support_services'].mean(),\n",
    "            'recommendation': 'Enhance academic support services'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "recommendations = generate_recommendations(df_model, model_results)\n",
    "print(\"\\nIntervention Recommendations:\")\n",
    "for area, details in recommendations.items():\n",
    "    print(f\"\\n{area.title()}:\")\n",
    "    print(f\"Pattern: {details['pattern']:.2f}\")\n",
    "    print(f\"Recommendation: {details['recommendation']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Future Trends Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def predict_future_trends(data):\n",
    "    \"\"\"Predict future educational trends.\"\"\"\n",
    "    if 'year' in data.columns:\n",
    "        # Analyze historical trends\n",
    "        yearly_trends = data.groupby('year').agg({\n",
    "            'success': 'mean',\n",
    "            'enrollment_rate': 'mean',\n",
    "            'dropout_rate': 'mean'\n",
    "        })\n",
    "        \n",
    "        # Plot trends\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        yearly_trends.plot()\n",
    "        plt.title('Educational Trends Over Time')\n",
    "        plt.xlabel('Year')\n",
    "        plt.ylabel('Rate')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "        # Simple projection for next year\n",
    "        projection = yearly_trends.diff().mean() + yearly_trends.iloc[-1]\n",
    "        print(\"\\nProjected Metrics for Next Year:\")\n",
    "        print(projection)\n",
    "\n",
    "predict_future_trends(df_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Key Insights and Recommendations\n",
    "\n",
    "### Predictive Factors\n",
    "1. Most influential factors in academic success:\n",
    "   - List top factors from model\n",
    "   - Quantify their impact\n",
    "   - Identify intervention points\n",
    "\n",
    "### Risk Patterns\n",
    "1. Common characteristics of at-risk students:\n",
    "   - Behavioral patterns\n",
    "   - Environmental factors\n",
    "   - Resource access issues\n",
    "\n",
    "### Intervention Strategies\n",
    "1. Targeted support programs:\n",
    "   - Early warning systems\n",
    "   - Resource allocation\n",
    "   - Support services\n",
    "\n",
    "### Future Outlook\n",
    "1. Projected trends:\n",
    "   - Success rates\n",
    "   - Risk factors\n",
    "   - Resource needs\n",
    "\n",
    "### Implementation Plan\n",
    "1. Short-term actions:\n",
    "   - Immediate interventions\n",
    "   - Resource deployment\n",
    "   - Monitoring setup\n",
    "\n",
    "2. Long-term strategy:\n",
    "   - System improvements\n",
    "   - Policy recommendations\n",
    "   - Capacity building"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
