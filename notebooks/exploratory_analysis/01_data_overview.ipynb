{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Overview and Initial Exploration\n",
    "\n",
    "This notebook provides a comprehensive overview of the Bangladesh student data, including:\n",
    "- Data structure and dimensions\n",
    "- Missing value analysis\n",
    "- Data type distributions\n",
    "- Initial statistical summaries\n",
    "- Data quality assessment\n",
    "\n",
    "**Data Sources:**\n",
    "- BANBEIS (Bangladesh Bureau of Educational Information and Statistics)\n",
    "- Education Board Results\n",
    "- DSHE (Directorate of Secondary and Higher Education)\n",
    "- DPE (Directorate of Primary Education)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to Python path\n",
    "sys.path.append('../..')\n",
    "from src.data_processing.data_processor import DataProcessor\n",
    "\n",
    "# Configure display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "plt.style.use('seaborn-v0_8')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "sns.set_palette('viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Initial Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize data processor\n",
    "processor = DataProcessor()\n",
    "\n",
    "# Load sample data (modify source as needed)\n",
    "try:\n",
    "    student_data = processor.load_student_data('academic')\n",
    "    print(f\"Data loaded successfully: {student_data.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "    # Create sample data for demonstration\n",
    "    student_data = pd.DataFrame({\n",
    "        'student_id': [f'S{i:04d}' for i in range(1, 1001)],\n",
    "        'name': [f'Student {i}' for i in range(1, 1001)],\n",
    "        'division': np.random.choice(['Dhaka', 'Chittagong', 'Khulna', 'Rajshahi', 'Sylhet'], 1000),\n",
    "        'district': np.random.choice(['Dhaka', 'Chittagong', 'Khulna', 'Rajshahi', 'Sylhet'], 1000),\n",
    "        'gender': np.random.choice(['Male', 'Female'], 1000),\n",
    "        'age': np.random.randint(15, 25, 1000),\n",
    "        'gpa': np.random.uniform(2.0, 5.0, 1000),\n",
    "        'attendance_rate': np.random.uniform(0.6, 1.0, 1000),\n",
    "        'socioeconomic_status': np.random.choice(['Low', 'Medium', 'High'], 1000)\n",
    "    })\n",
    "    print(\"Sample data created for demonstration\")\n",
    "\n",
    "# Display basic information\n",
    "print(f\"\\nDataset Shape: {student_data.shape}\")\n",
    "print(f\"Number of students: {len(student_data):,}\")\n",
    "print(f\"Number of features: {len(student_data.columns)}\")\n",
    "\n",
    "# Show first few rows\n",
    "student_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Structure Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Data types and info\n",
    "print(\"Data Types:\")\n",
    "print(student_data.dtypes)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Memory usage\n",
    "print(\"Memory Usage:\")\n",
    "print(student_data.info(memory_usage='deep'))\n",
    "\n",
    "# Column names\n",
    "print(f\"\\nColumn Names ({len(student_data.columns)}):\")\n",
    "for i, col in enumerate(student_data.columns, 1):\n",
    "    print(f\"{i:2d}. {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Missing Value Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Missing value analysis\n",
    "missing_data = pd.DataFrame({\n",
    "    'Column': student_data.columns,\n",
    "    'Missing_Count': student_data.isnull().sum(),\n",
    "    'Missing_Percentage': (student_data.isnull().sum() / len(student_data)) * 100\n",
    "})\n",
    "\n",
    "missing_data = missing_data.sort_values('Missing_Percentage', ascending=False)\n",
    "missing_data = missing_data[missing_data['Missing_Count'] > 0]\n",
    "\n",
    "if len(missing_data) > 0:\n",
    "    print(\"Missing Values Summary:\")\n",
    "    print(missing_data)\n",
    "    \n",
    "    # Visualize missing values\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Missing values heatmap\n",
    "    sns.heatmap(student_data.isnull(), yticklabels=False, cbar=True, ax=ax1)\n",
    "    ax1.set_title('Missing Values Heatmap')\n",
    "    \n",
    "    # Missing values bar plot\n",
    "    missing_data.plot(x='Column', y='Missing_Percentage', kind='bar', ax=ax2)\n",
    "    ax2.set_title('Missing Values Percentage by Column')\n",
    "    ax2.set_ylabel('Missing Percentage (%)')\n",
    "    ax2.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No missing values found in the dataset!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Statistical Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Numerical columns summary\n",
    "numerical_cols = student_data.select_dtypes(include=[np.number]).columns\n",
    "print(\"Numerical Columns Summary:\")\n",
    "print(student_data[numerical_cols].describe())\n",
    "\n",
    "# Categorical columns summary\n",
    "categorical_cols = student_data.select_dtypes(include=['object']).columns\n",
    "print(\"\\nCategorical Columns Summary:\")\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(student_data[col].value_counts())\n",
    "    print(f\"Unique values: {student_data[col].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Distribution Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Distribution plots for numerical variables\n",
    "if len(numerical_cols) > 0:\n",
    "    n_cols = min(3, len(numerical_cols))\n",
    "    n_rows = (len(numerical_cols) + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5*n_rows))\n",
    "    if n_rows == 1:\n",
    "        axes = [axes] if n_cols == 1 else axes\n",
    "    else:\n",
    "        axes = axes.flatten()\n",
    "    \n",
    "    for i, col in enumerate(numerical_cols):\n",
    "        ax = axes[i] if len(numerical_cols) > 1 else axes\n",
    "        \n",
    "        # Histogram with KDE\n",
    "        sns.histplot(data=student_data, x=col, kde=True, ax=ax)\n",
    "        ax.set_title(f'Distribution of {col}')\n",
    "        ax.set_ylabel('Frequency')\n",
    "    \n",
    "    # Hide empty subplots\n",
    "    for i in range(len(numerical_cols), len(axes)):\n",
    "        axes[i].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Geographic Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Geographic distribution analysis\n",
    "if 'division' in student_data.columns:\n",
    "    division_counts = student_data['division'].value_counts()\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Bar plot\n",
    "    division_counts.plot(kind='bar', ax=ax1)\n",
    "    ax1.set_title('Student Distribution by Division')\n",
    "    ax1.set_ylabel('Number of Students')\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Pie chart\n",
    "    ax2.pie(division_counts.values, labels=division_counts.index, autopct='%1.1f%%')\n",
    "    ax2.set_title('Student Distribution by Division (Percentage)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Interactive plotly visualization\n",
    "    fig_plotly = px.bar(\n",
    "        x=division_counts.index, \n",
    "        y=division_counts.values,\n",
    "        title='Interactive Student Distribution by Division',\n",
    "        labels={'x': 'Division', 'y': 'Number of Students'}\n",
    "    )\n",
    "    fig_plotly.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Correlation analysis for numerical variables\n",
    "if len(numerical_cols) > 1:\n",
    "    correlation_matrix = student_data[numerical_cols].corr()\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "                square=True, linewidths=0.5)\n",
    "    plt.title('Correlation Matrix of Numerical Variables')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Find highly correlated pairs\n",
    "    high_corr = []\n",
    "    for i in range(len(correlation_matrix.columns)):\n",
    "        for j in range(i+1, len(correlation_matrix.columns)):\n",
    "            if abs(correlation_matrix.iloc[i, j]) > 0.7:\n",
    "                high_corr.append((\n",
    "                    correlation_matrix.columns[i],\n",
    "                    correlation_matrix.columns[j],\n",
    "                    correlation_matrix.iloc[i, j]\n",
    "                ))\n",
    "    \n",
    "    if high_corr:\n",
    "        print(\"\\nHighly Correlated Variable Pairs (|r| > 0.7):\")\n",
    "        for var1, var2, corr in high_corr:\n",
    "            print(f\"{var1} - {var2}: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Data quality assessment\n",
    "def assess_data_quality(df):\n",
    "    \"\"\"Comprehensive data quality assessment.\"\"\"\n",
    "    quality_report = {}\n",
    "    \n",
    "    # Basic metrics\n",
    "    quality_report['total_records'] = len(df)\n",
    "    quality_report['total_features'] = len(df.columns)\n",
    "    quality_report['missing_values_total'] = df.isnull().sum().sum()\n",
    "    quality_report['missing_percentage'] = (df.isnull().sum().sum() / (len(df) * len(df.columns))) * 100\n",
    "    \n",
    "    # Duplicates\n",
    "    quality_report['duplicate_records'] = df.duplicated().sum()\n",
    "    quality_report['duplicate_percentage'] = (df.duplicated().sum() / len(df)) * 100\n",
    "    \n",
    "    # Data types\n",
    "    quality_report['data_types'] = df.dtypes.value_counts().to_dict()\n",
    "    \n",
    "    return quality_report\n",
    "\n",
    "# Generate quality report\n",
    "quality_report = assess_data_quality(student_data)\n",
    "\n",
    "print(\"DATA QUALITY REPORT\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total Records: {quality_report['total_records']:,}\")\n",
    "print(f\"Total Features: {quality_report['total_features']}\")\n",
    "print(f\"Missing Values: {quality_report['missing_values_total']:,} ({quality_report['missing_percentage']:.2f}%)\")\n",
    "print(f\"Duplicate Records: {quality_report['duplicate_records']:,} ({quality_report['duplicate_percentage']:.2f}%)\")\n",
    "print(f\"\\nData Types Distribution:\")\n",
    "for dtype, count in quality_report['data_types'].items():\n",
    "    print(f\"  {dtype}: {count} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Key Insights Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Generate key insights\n",
    "print(\"KEY INSIGHTS FROM EXPLORATORY ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Dataset overview\n",
    "print(f\"📊 Dataset contains {len(student_data):,} student records with {len(student_data.columns)} features\")\n",
    "\n",
    "# Geographic distribution\n",
    "if 'division' in student_data.columns:\n",
    "    most_represented = student_data['division'].mode()[0]\n",
    "    print(f\"🗺️  Most represented division: {most_represented}\")\n",
    "\n",
    "# Performance insights\n",
    "if 'gpa' in student_data.columns:\n",
    "    avg_gpa = student_data['gpa'].mean()\n",
    "    print(f\"📈 Average GPA: {avg_gpa:.2f}\")\n",
    "\n",
    "# Gender distribution\n",
    "if 'gender' in student_data.columns:\n",
    "    gender_dist = student_data['gender'].value_counts(normalize=True) * 100\n",
    "    print(f\"👥 Gender distribution: {dict(gender_dist.round(1))}\")\n",
    "\n",
    "# Data quality\n",
    "if quality_report['missing_percentage'] < 5:\n",
    "    print(f\"✅ Data quality is good - only {quality_report['missing_percentage']:.1f}% missing values\")\n",
    "else:\n",
    "    print(f\"⚠️  Data quality needs attention - {quality_report['missing_percentage']:.1f}% missing values\")\n",
    "\n",
    "print(\"\\n📝 Recommendations for next steps:\")\n",
    "print(\"   • Proceed with demographic analysis\")\n",
    "print(\"   • Investigate performance patterns\")\n",
    "print(\"   • Analyze geographic variations\")\n",
    "print(\"   • Examine socioeconomic factors\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
